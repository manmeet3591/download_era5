# -*- coding: utf-8 -*-
"""wind_era5_land_hourly.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y3EPpWLy4sUrs0MkjxMgf65a9eXiYrWj
"""

!pip install --no-cache-dir zarr==2.14.2 numcodecs==0.11.0

import fsspec

fs = fsspec.filesystem('gs', token='anon')
fs.ls('gs://gcp-public-data-arco-era5/co/')

import fsspec
import xarray as xr

reanalysis = xr.open_zarr(
    'gs://gcp-public-data-arco-era5/co/single-level-reanalysis.zarr',
    chunks={'time': 48},storage_options={'token': 'anon'},
    consolidated=True
)
reanalysis

print(f'size: {reanalysis.nbytes / (1024 ** 4)} TiB')

reanalysis

recent_an = reanalysis.sel(time=slice('2020-01-01', '2021-01-01'))

geopotential_t0 = recent_an.z[0, :]
most_recent_ds = recent_an.isel(time=-1)
new_years_ds = recent_an.sel(time='2020-01-01')

def lon_to_360(dlon: float) -> float:
  return ((360 + (dlon % 360)) % 360)
# First, compute the condition mask
mask = (
    (recent_an.longitude > lon_to_360(-171.79)) &
    (recent_an.longitude < lon_to_360(-66.96)) &
    (recent_an.latitude > 18.91) &
    (recent_an.latitude < 71.35)
).compute()

# Then apply it to the dataset
US_ds = recent_an.where(mask, drop=True)

US_ds

import xarray as xr
import scipy.spatial
import numpy as np

def mirror_point_at_360(ds):
    # Compute the mask to avoid Dask shape ambiguity
    mask = (ds.longitude == 0).compute()
    extra_point = (
        ds.where(mask, drop=True)
        .assign_coords(longitude=lambda x: x.longitude + 360)
    )
    return xr.concat([ds, extra_point], dim='values')


def build_triangulation(x, y):
  grid = np.stack([x, y], axis=1)
  return scipy.spatial.Delaunay(grid)

def interpolate(data, tri, mesh):
  indices = tri.find_simplex(mesh)
  ndim = tri.transform.shape[-1]
  T_inv = tri.transform[indices, :ndim, :]
  r = tri.transform[indices, ndim, :]
  c = np.einsum('...ij,...j', T_inv, mesh - r)
  c = np.concatenate([c, 1 - c.sum(axis=-1, keepdims=True)], axis=-1)
  result = np.einsum('...i,...i', data[:, tri.simplices[indices]], c)
  return np.where(indices == -1, np.nan, result)

# Commented out IPython magic to ensure Python compatibility.
# %time ds_feb20 = reanalysis.sel(time=slice('2020-02-01', '2020-02-28')).pipe(mirror_point_at_360)

# Commented out IPython magic to ensure Python compatibility.
# %time tri = build_triangulation(ds_feb20.longitude, ds_feb20.latitude)

# Commented out IPython magic to ensure Python compatibility.
longitude = np.linspace(0, 360, num=360*4+1)
latitude = np.linspace(-90, 90, num=180*4+1)
mesh = np.stack(np.meshgrid(longitude, latitude, indexing='ij'), axis=-1)
# %time d2m_mesh = interpolate(ds_feb20.d2m.values, tri, mesh)
d2m_feb20 = xr.DataArray(d2m_mesh, coords=[('time', ds_feb20.time.data), ('longitude', longitude), ('latitude', latitude)])

d2m_feb20[0].plot(x='longitude', y='latitude', cmap='viridis', size=7, aspect=2, add_colorbar=False, robust=True)

# Zoom into India...
# W: 68.1766451354, S: 7.96553477623, E: 97.4025614766, N: 35.4940095078
(
    d2m_feb20
    .sel(latitude=slice(7.965, 35.494), longitude=slice(lon_to_360(68.176), lon_to_360(97.402)))
    .isel(time=0)
    .plot(x='longitude', y='latitude', cmap='viridis', size=7, aspect=2, add_colorbar=False, robust=True)
)